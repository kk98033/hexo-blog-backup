---
title: 透過 RAG 技術強化 LLM 資訊檢索並明確呈現來源追溯-實作篇
date: 2024-04-03 10:21:51
tags:
  - LLM
categories:
  - 學習筆記
excerpt: 最近在解決 LLM 回答問題準確度的問題，我找到了一項名為 RAG（Retrieval-Augmented Generation）的技術，這是一種旨在提升大型語言模型回答品質的方法。 RAG 通過先行檢索相關資料，然後基於這些資料生成回答，這種方式不僅可以增強了模型的回答能力，還提供了一種機制來追溯資訊源頭。
description: 本篇文章將會使用之前所提到的 RAG 技術，實作一個可以返回資訊來源的 LLM
---

# 透過 RAG 技術強化 LLM 資訊檢索並明確呈現來源追溯-實作篇

本篇文章將會使用上一篇文章所提到的 [RAG](https://blog.iddle.dev/public/2024/04/02/%E9%80%8F%E9%81%8E-RAG-%E6%8A%80%E8%A1%93%E5%BC%B7%E5%8C%96-LLM-%E8%B3%87%E8%A8%8A%E6%AA%A2%E7%B4%A2%E4%B8%A6%E6%98%8E%E7%A2%BA%E5%91%88%E7%8F%BE%E4%BE%86%E6%BA%90%E8%BF%BD%E6%BA%AF/) 技術，實作一個可以返回資訊來源的 LLM

接下來我會參考這篇 [blog](https://zilliz.com/blog/retrieval-augmented-generation-with-citations) 的文章（文章裡面的 LlamaIndex 語法跟目前的版本有所差異 -_-），在 Google Colab 使用 [Milvus](https://milvus.io/) 和 [LlamaIndex](https://docs.llamaindex.ai/en/stable/) 搭建一個基於大型語言模型（LLM）的檢索增強生成模型（RAG）查詢引擎。

此專案會使用到：
1. Milvus：Milvus 是一個開源的向量數據庫，專為提供高效的相似性搜索和向量索引而設計。它能夠處理大規模的向量數據，適用於各種AI應用，如推薦系統、影像識別和自然語言處理等。
2. Milvus Lite：Milvus Lite 是 Milvus 的輕量版本，專為與 Google Colab 和 Jupyter Notebook 無縫配合而設計。
3. LlamaIndex：LlamaIndex 是一個為語言模型設計的索引和檢索框架，它提供了建立、管理和利用索引來增強語言模型檢索性能的工具。
4. OpenAI embeddings：我們使用他語義檢索技術來增強大型語言模型（LLM）的能力，以及利用其生成向量嵌入的能力來改善文檔檢索的精確度和相關性。

### 安裝相關套件
{% codeblock [line_number:true] [highlight:true]%}
!pip install milvus
!pip install milvus python-dotenv
!pip install llama-index
!pip install llama-index-vector-stores-milvus
{% endcodeblock %}

### Import 相關套件
{% note danger %}
注意！ 設定 OpenAI api key 環境變數要放在 import SimpleDirectoryReader 之前，不然會讀不到
{% endnote %}