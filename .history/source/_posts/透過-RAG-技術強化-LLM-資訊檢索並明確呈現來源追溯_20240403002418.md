---
layout: blog
title: 透過 RAG 技術強化 LLM 資訊檢索並明確呈現來源追溯
date: 2024-04-02 23:58:40
tags:
  - 網站開發
categories:
  - 學習筆記
excerpt: 最近在解決 LLM 回答問題準確度的問題，我找到了一項名為 RAG（Retrieval-Augmented Generation）的技術，這是一種旨在提升大型語言模型回答品質的方法。 RAG 通過先行檢索相關資料，然後基於這些資料生成回答，這種方式不僅可以增強了模型的回答能力，還提供了一種機制來追溯資訊源頭。
description: 最近在解決 LLM 回答問題準確度的問題，我找到了一項名為 RAG（Retrieval-Augmented Generation）的技術，這是一種旨在提升大型語言模型回答品質的方法。 RAG 通過先行檢索相關資料，然後基於這些資料生成回答，這種方式不僅可以增強了模型的回答能力，還提供了一種機制來追溯資訊源頭。
---
# 透過 RAG 技術強化 LLM 資訊檢索並明確呈現來源追溯

最近在解決 LLM 回答問題準確度的問題，我找到了一項名為 **RAG（Retrieval-Augmented Generation）** 的技術，這是一種旨在提升大型語言模型回答品質的方法。 RAG 通過先行檢索相關資料，然後基於這些資料生成回答，這種方式不僅可以增強了模型的回答能力，還提供了一種機制來追溯資訊源頭。

## 什麼是RAG (Retrieval-Augmented Generation)？
RAG 是一種將資訊檢索（Retrieval）與文本生成（Generation）相結合，來強化大型語言模型（LLM）的技術。這種方法允許模型在生成回答之前，先從一個外部知識庫中檢索相關資訊，從而提供更加準確和豐富的回答​
簡單來說，當用戶提出問題時，RAG 首先從知識庫中搜尋與該問題相關的答案，然後將這些檢索到的資訊整合到一個新的 prompt 中，這個 prompt 包括了原始查詢和檢索到的信息，最後由 LLM 生成包含檢索信息的回答。這種方式類似於 “開卷考試” ，模型在回答問題時可以參考 “書本” 中的內容，而不是完全依賴於記憶中的事實

{% img [class names] https://blog.iddle.dev/public/2023/04/09/%E5%A6%82%E4%BD%95%E5%9C%A8Google%E6%90%9C%E5%B0%8B%E5%88%B0%E6%88%91%E7%9A%84%E7%B6%B2%E7%AB%99%EF%BC%9FGoogle-Search-Console%E6%95%99%E5%AD%B8%E4%BB%A5%E5%8F%8ASEO%E5%84%AA%E5%8C%96/site.png  512 '"RAG 的運作方式" "RAG 的運作方式"' %}

[圖片來源：AWS 檢索增強生成（RAG）](https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html)

## RAG有哪些優點？
## RAG的運作方式
## RAG與Fine-tuning的比較